# Alibaba AMAP CV Lab

[ä¸­æ–‡é˜…è¯»](README_zh.md)

# ğŸ‘‹ About Us

We are the Alibaba AMAP CV Lab, focusing on cutting-edge research and innovative applications centered around computer vision technology. We are dedicated to building core technological capabilities in the field of spatiotemporal internet. The Alibaba AMAP CV Lab is always at the forefront of innovation in computer vision research and applications, making it a key practitioner of technology in the field of Alibabaâ€™s spatial intelligent internet. The Alibaba AMAP CV team is located at the intersection of the physical and digital worlds, empowering smart mobility and daily life with AI. As a core technical driver within Amap, our team pioneers:
- **Next-Generation 3D Map Engines**  
- **Multimodal Understanding & Generation**  
- **Spatial Intelligence**  
- **World Modeling**
---

_We welcome contributions, issues, and feedback!_  
Feel free to â­ the repos above to stay updated.

# ğŸ”ˆ Latest News

- ğŸ› **Apr 29, 2025** â€“ Our paper [**G3PT**](https://arxiv.org/abs/2409.06322) is accepted by IJCAI 2025.
- ğŸ“¢ **Apr 28, 2025** â€“ We released the inference code and model weights of [**FantasyTalking**](https://fantasy-amap.github.io/fantasy-talking/).  
- ğŸ“¢ **Apr 24, 2025** â€“ We released the inference code and model weights of [**FantasyID**](https://fantasy-amap.github.io/fantasy-id/).

# ğŸ”§ Public Technologies

<!-- 

3D Map Engine

-->

## ğŸ—ºï¸ 3D Map Engine  

Next-generation engine for real-time rendering and updating of large-scale 3D maps with high-level accuracy.  

### ğŸ“‘ Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map 

[![Home Page](https://img.shields.io/badge/ğŸŒ%20%20Project-MapDR-blue.svg)](https://miv-xjtu.github.io/MapDR/)
[![arXiv](https://img.shields.io/badge/Arxiv-2410.23780-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2410.23780)
[![Publish](https://img.shields.io/badge/ğŸ›%20%20Conference-CVPR%202025-green)](https://arxiv.org/abs/2410.23780)

<!-- [![Publish](https://img.shields.io/badge/Conference-CVPR%202025-green?logo=ieee&logoColor=white&style=flat)](https://arxiv.org/abs/2410.23780) -->
<!-- ![Open Access](https://img.shields.io/badge/Open%20Access-Free-F68212?logo=openaccess&logoColor=white&style=flat-square) -->

Benchmark and multi-modal approach for integrating lane-level traffic sign regulations into vectorized HD maps.

### ğŸ“‘ Global-Guided Focal Neural Radiance Field for Large-Scale Scene Representation

[![Home Page](https://img.shields.io/badge/ğŸŒ%20%20Project-GF%20NeRF-blue.svg)](https://shaomq2187.github.io/GF-NeRF/)
[![arXiv](https://img.shields.io/badge/Arxiv-2403.12839-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2403.12839)
[![Publish](https://img.shields.io/badge/ğŸ›%20%20Conference-WACV%202025-green)](https://ieeexplore.ieee.org/abstract/document/10943871)

<!-- 

Multimodal AI

-->

## ğŸŒˆ Multimodal AI  
Toolkit for unified understanding and generation across text, image, video, audio and spatial data.  

### ğŸ“‘ G3PT: Unleash the Power of Autoregressive Modeling in 3D Generative Tasks

[![arXiv](https://img.shields.io/badge/Arxiv-2409.06322-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2409.06322) 
[![Publish](https://img.shields.io/badge/ğŸ›%20%20Conference-IJCAI%202025-green)](https://arxiv.org/abs/2409.06322)

The first native 3D generation foundational model based on next-scale autoregression.

### ğŸ“‘ A Study on the Adverse Impact of Synthetic Speech on Speech Recognition

[![Publish](https://img.shields.io/badge/ğŸ›%20%20Conference-ICASSP%202024-green)](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10446991)

<!-- 

Human AIGC

-->

## ğŸ¤– Human AIGC

The human related AIGC model family, more are coming soon. Please check out our [Fantasy AIGC Family](https://github.com/Fantasy-AMAP) for more details.

### ğŸ—£ï¸ FantasyTalking: Realistic Talking Portrait Generation via Coherent Motion Synthesis
  
[![Home Page](https://img.shields.io/badge/ğŸŒ%20%20Project-FantasyTalking-blue.svg)](https://fantasy-amap.github.io/fantasy-talking/)
[![arXiv](https://img.shields.io/badge/Arxiv-2504.04842-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2504.04842)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace-FFD21E.svg)](https://huggingface.co/acvlab/FantasyID)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-Space-FFD21E.svg)](https://huggingface.co/spaces/acvlab/FantasyTalking)
[![ModelScope](https://img.shields.io/badge/ğŸ¤–-ModelScope-604DF4.svg)](https://modelscope.cn/models/amap_cvlab/FantasyTalking)
[![Code](https://img.shields.io/badge/Code-GitHub-181717.svg)](https://github.com/Fantasy-AMAP/fantasy-talking)

The first Wan based high-fidelity audio-driven avatar system that synchronizes facial expressions, lip motion, and body gestures in dynamic scenes. 

### ğŸ†” FantasyID: Face Knowledge Enhanced ID-Preserving Video Generation

[![Home Page](https://img.shields.io/badge/ğŸŒ%20%20Project-FantasyID-blue.svg)](https://fantasy-amap.github.io/fantasy-id/)
[![arXiv](https://img.shields.io/badge/Arxiv-2502.13995-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2502.13995)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace-FFD21E.svg)](https://huggingface.co/acvlab/FantasyID)
[![ModelScope](https://img.shields.io/badge/ğŸ¤–-ModelScope-604DF4.svg)](https://modelscope.cn/models/amap_cvlab/FantasyID)
[![Code](https://img.shields.io/badge/GitHub-Code-181717.svg?logo=GitHub)](https://github.com/Fantasy-AMAP/fantasy-id)

A tuning-free text-to-video model that leverages 3D facial priors, multi-view augmentation, and layer-aware guidance injection to deliver dynamic, identity-preserving video generation.

### ğŸ“‘ HumanRig: Learning Automatic Rigging for Humanoid Characters in Animation

[![Home Page](https://img.shields.io/badge/ğŸŒ%20%20Project-HumanRig-blue.svg)](https://c8241998.github.io/HumanRig/)
[![arXiv](https://img.shields.io/badge/Arxiv-2412.02317-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2412.02317)
[![Publish](https://img.shields.io/badge/ğŸ›%20%20Conference-CVPR%202025-green)](https://arxiv.org/abs/2412.02317)
[![Code](https://img.shields.io/badge/GitHub-Code-181717.svg?logo=GitHub)](https://github.com/c8241998/HumanRig)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-Datasets-FFD21E.svg)](https://huggingface.co/datasets/jellyczd/HumanRig)

The first dataset for automatic rigging of 3D generated digital humans and a transformer-based end-to-end automatic rigging algorithm.


<!-- 

Comming Soon

-->


## ğŸ“ Spatial Intelligence  
Framework for spatial reasoning and path planning in autonomous navigation and robotics.  
ğŸ”œ Coming soon

## ğŸŒ World Modeling  
Platform for constructing and querying dynamic digital twins of real-world environments.  
ğŸ”œ Coming soon

<!-- 

Human AIGC

-->

## ğŸ’¡ Others


### ğŸ“‘ DPOSE: Online Keypoint-CAM Guided Inference for Driver Pose Estimation

[![Publish](https://img.shields.io/badge/ğŸ›%20%20Conference-CVPR%202023-green)](https://openaccess.thecvf.com/content/CVPRW2023/html/w14/Wang_DPOSE_Online_Keypoint-CAM_Guided_Inference_for_Driver_Pose_Estimation_With_CVPRW_2023_paper.html)


### ğŸ¤– Doubly-Fused ViT: Fuse Information from Dual Vision Transformer Streams

[![Publish](https://img.shields.io/badge/ğŸ›%20%20Conference-ECCV%202022-green)](https://www.ecva.net/papers/eccv_2022/papers/136830723.pdf)
[![Code](https://img.shields.io/badge/GitHub-Code-181717.svg?logo=GitHub)](https://github.com/ginobilinie/DFvT)

### ğŸ“‘ SCMT: Self-Correction Mean Teacher for Semi-supervised Object Detection

[![Publish](https://img.shields.io/badge/ğŸ›%20%20Conference-IJCAI%202022-green)](https://www.ijcai.org/proceedings/2022/0207.pdf)

A self-correction mean teacher architecture that mitigates the impact of noisy pseudo-labels, offering a novel technological breakthrough in the field of semi-supervised object detection.
